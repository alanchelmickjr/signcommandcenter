#!/bin/bash
# ASL Command Center - Quick Start Script for Berkeley Cal Hacks 2025
#
# DEBUGGING NOTES:
# - Claude 3.5 previously installed conflicting llama-server versions
# - /usr/local/bin/llama-server has library issues (libmtmd.dylib)
# - /opt/homebrew/bin/llama-server works correctly
# - Always use the Homebrew version for stability
# - Future custom llama.cpp builds should go in different location
#
# MODEL NOTES:
# - Primary model: ggml-org/SmolVLM-500M-Instruct-GGUF (M2 compatible)
# - Fallback for non-Apple: HuggingFaceTB/SmolVLM-500M-Instruct
# - Actual files: SmolVLM-500M-Instruct-Q8_0.gguf + mmproj-SmolVLM-500M-Instruct-Q8_0.gguf

echo "ðŸ¤Ÿ ASL Command Center - Berkeley Cal Hacks 2025"
echo "=============================================="

# Check if we're in the right directory
if [ ! -f "index.html" ]; then
    echo "âŒ Error: Please run this script from the project directory (where index.html is located)"
    exit 1
fi

# Create directories for model storage and training data
echo "ðŸ“ Setting up directories..."
mkdir -p models/SmolVLM
mkdir -p training_data/asl_signs
mkdir -p training_data/annotations

# Auto-train model if needed
echo "ðŸŽ“ Checking for trained ASL model..."
if [ ! -f "models/asl_patterns.json" ] && [ ! -d "models/smolvlm_asl" ]; then
    echo "ðŸš€ No model found - triggering auto-training..."
    cd ml_training
    if $PYTHON_CMD train_asl_model.py; then
        echo "âœ… Auto-training completed successfully!"
        cd ..
    else
        echo "âš ï¸  Auto-training failed - system will use default patterns"
        cd ..
    fi
else
    echo "âœ… Trained model found - skipping auto-training"
fi

# Kill any existing processes first (be specific about llama-server path)
echo "ðŸ§¹ Cleaning up any existing processes..."
pkill -f "python.*asl_server" 2>/dev/null || true
pkill -f "python.*robot_executor" 2>/dev/null || true
pkill -f "python.*https-server" 2>/dev/null || true
pkill -f "python.*http.server" 2>/dev/null || true
pkill -f "node.*gun-relay" 2>/dev/null || true
pkill -f "/opt/homebrew/bin/llama-server" 2>/dev/null || true
pkill -f "/usr/local/bin/llama-server" 2>/dev/null || true  # Clean up broken installation too

# Kill processes on specific ports to ensure they're free - AGGRESSIVE MODE
echo "ðŸ”§ Force-killing processes on target ports..."

# Force kill processes on all target ports
for port in 5001 8080 8765 8000 8443; do
    echo "  ðŸŽ¯ Clearing port $port..."
    lsof -ti:$port | xargs kill -9 2>/dev/null || true
    # Wait and check again
    sleep 1
    if lsof -i:$port >/dev/null 2>&1; then
        echo "  âš ï¸  Port $port still occupied, trying sudo kill..."
        sudo lsof -ti:$port | xargs sudo kill -9 2>/dev/null || true
    fi
done

echo "âœ… Port cleanup complete"
sleep 5

echo "ðŸ“‹ Checking requirements..."

# Check for Python
if command -v python3 &> /dev/null; then
    PYTHON_CMD="python3"
elif command -v python &> /dev/null; then
    PYTHON_CMD="python"
else
    echo "âŒ Python not found. Please install Python to run the ASL server."
    exit 1
fi

echo "âœ… Python found: $PYTHON_CMD"

# Install Python dependencies for ASL system
echo "ðŸ“¦ Installing ASL system dependencies..."
if [ -f "requirements_asl.txt" ]; then
    $PYTHON_CMD -m pip install -r requirements_asl.txt
    echo "âœ… ASL dependencies installed"
else
    echo "âš ï¸  requirements_asl.txt not found. Installing basic dependencies..."
    $PYTHON_CMD -m pip install flask flask-cors requests python-dotenv
fi

# Check for Node.js (needed for Gun.js relay)
if ! command -v node &> /dev/null; then
    echo "âŒ Node.js not found. Installing Node.js for data persistence..."
    if command -v brew &> /dev/null; then
        brew install node
    else
        echo "âŒ Please install Node.js manually from https://nodejs.org/"
        echo "   Gun.js data persistence will be limited without relay server"
    fi
else
    echo "âœ… Node.js found"
fi

# Check for llama-server (use Homebrew version to avoid library conflicts)
LLAMA_SERVER="/opt/homebrew/bin/llama-server"
if [ ! -f "$LLAMA_SERVER" ]; then
    echo "ðŸ¤– Setting up your personal ASL AI assistant (this keeps you safe!)"
    echo "ðŸ“¥ Installing llama.cpp automatically..."
    echo "ðŸ”’ This protects your privacy - everything stays on your device"
    echo "â±ï¸  One-time setup takes 2-3 minutes, then it's instant forever"
    echo ""
    
    # Auto-install llama.cpp via Homebrew
    if command -v brew &> /dev/null; then
        echo "ðŸº Installing via Homebrew..."
        brew install llama.cpp
        if [ $? -eq 0 ] && [ -f "$LLAMA_SERVER" ]; then
            echo "âœ… llama.cpp installed successfully!"
            AI_SERVER=true
        else
            echo "âŒ Installation failed. AI features will be disabled."
            AI_SERVER=false
        fi
    else
        echo "âŒ Homebrew not found. Please install Homebrew first:"
        echo "   /bin/bash -c \"\$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\""
        AI_SERVER=false
    fi
else
    echo "âœ… llama-server found (Homebrew version)"
    # Test if llama-server works properly
    if "$LLAMA_SERVER" --help >/dev/null 2>&1; then
        AI_SERVER=true
    else
        echo "âš ï¸  llama-server has issues. Trying to fix..."
        if command -v brew &> /dev/null; then
            brew reinstall llama.cpp
            if [ $? -eq 0 ]; then
                echo "âœ… llama-server fixed!"
                AI_SERVER=true
            else
                echo "âŒ Could not fix llama-server. AI features will be disabled."
                AI_SERVER=false
            fi
        else
            echo "âŒ Cannot fix llama-server without Homebrew. AI features will be disabled."
            AI_SERVER=false
        fi
    fi
fi

# Download GGUF model if not present
download_model() {
    echo "ðŸ“¥ Downloading SmolVLM model for ASL recognition..."
    local model_dir="models/SmolVLM"
    local model_file="$model_dir/SmolVLM-500M-Instruct-Q8_0.gguf"
    local mmproj_file="$model_dir/mmproj-SmolVLM-500M-Instruct-Q8_0.gguf"
    
    # Check if model files exist
    if [ ! -f "$model_file" ] || [ ! -f "$mmproj_file" ]; then
        echo "ðŸ”½ Model files not found locally. Downloading..."
        
        # Use huggingface-hub to download
        if command -v huggingface-cli &> /dev/null; then
            echo "ðŸ“¦ Using huggingface-cli to download model..."
            huggingface-cli download ggml-org/SmolVLM-500M-Instruct-GGUF SmolVLM-500M-Instruct-Q8_0.gguf --local-dir "$model_dir"
            huggingface-cli download ggml-org/SmolVLM-500M-Instruct-GGUF mmproj-SmolVLM-500M-Instruct-Q8_0.gguf --local-dir "$model_dir"
        else
            echo "ðŸ“¦ Installing huggingface-hub for model download..."
            $PYTHON_CMD -m pip install huggingface-hub[cli]
            if [ $? -eq 0 ]; then
                huggingface-cli download ggml-org/SmolVLM-500M-Instruct-GGUF SmolVLM-500M-Instruct-Q8_0.gguf --local-dir "$model_dir"
                huggingface-cli download ggml-org/SmolVLM-500M-Instruct-GGUF mmproj-SmolVLM-500M-Instruct-Q8_0.gguf --local-dir "$model_dir"
            else
                echo "âš ï¸  Could not install huggingface-hub. Model will be downloaded by llama-server on first run."
            fi
        fi
        
        if [ -f "$model_file" ] && [ -f "$mmproj_file" ]; then
            echo "âœ… Model files downloaded successfully!"
            return 0
        else
            echo "âš ï¸  Model files not found locally. Will download on first llama-server run."
            return 1
        fi
    else
        echo "âœ… Model files found locally"
        return 0
    fi
}

if [ "$AI_SERVER" = true ]; then
    download_model
    
    # Auto-train ASL model if no training exists
    echo "ðŸŽ“ Checking ASL model training status..."
    if [ ! -d "ml_training/asl_model_checkpoints" ] || [ ! -f "ml_training/asl_model_checkpoints/baseline_model.json" ]; then
        echo "ðŸš€ First boot detected - setting up ASL recognition training..."
        cd ml_training
        if $PYTHON_CMD train_asl_model.py; then
            echo "âœ… ASL baseline model created successfully!"
        else
            echo "âš ï¸  ASL training setup had issues, but system will still work"
        fi
        cd ..
    else
        echo "âœ… ASL model training already exists"
    fi
fi

# Find available ports
# Removed dynamic port finding - using fixed ports for demo stability  
# find_available_port() {
#     local start_port=$1
#     local port=$start_port
#     while lsof -Pi :$port -sTCP:LISTEN -t >/dev/null 2>&1; do
#         port=$((port + 1))
#     done
#     echo $port
# }

# Fixed ports for demo stability - no dynamic assignment
WEB_PORT=8000
AI_PORT=8080  
GUN_PORT=8765
ASL_PORT=5001
HTTPS_PORT=8443

echo "ðŸŒ Using fixed ports for demo:"
echo "   ðŸ“¦ Web Server: $WEB_PORT"
echo "   ðŸ¤– AI Server: $AI_PORT"  
echo "   ðŸ“¡ Gun.js Relay: $GUN_PORT"
echo "   ðŸ¤Ÿ ASL Server: $ASL_PORT"
echo "   ðŸ”’ HTTPS Server: $HTTPS_PORT"
if [ $GUN_PORT -ne 8765 ]; then
    echo "âš ï¸  Port 8765 is busy. Using port $GUN_PORT for Gun.js relay."
fi
if [ $ASL_PORT -ne 5000 ]; then
    echo "âš ï¸  Port 5000 is busy. Using port $ASL_PORT for ASL server."
fi
if [ $HTTPS_PORT -ne 8443 ]; then
    echo "âš ï¸  Port 8443 is busy. Using port $HTTPS_PORT for HTTPS server."
fi

# Create temporary Gun.js relay server file
echo "const Gun = require('gun');
const server = require('http').createServer().listen($GUN_PORT);
const gun = Gun({web: server});
console.log('Gun.js relay server started on port $GUN_PORT');" > gun-relay.js

# Install Gun.js if not available
if ! npm list gun &> /dev/null; then
    echo "ðŸ“¦ Installing Gun.js for data persistence..."
    npm install gun --no-save &> /dev/null || {
        echo "âš ï¸  Gun.js installation failed. Data persistence may be limited."
    }
fi

# Start Gun.js relay server
echo "ðŸ“¦ Starting Gun.js relay server on port $GUN_PORT..."
node gun-relay.js > gun-relay.log 2>&1 &
GUN_PID=$!

# Function to cleanup background processes
cleanup() {
    echo ""
    echo "ðŸ›‘ Shutting down servers..."
    
    # Kill processes by PID if available
    if [ ! -z "$WEB_PID" ] && kill -0 $WEB_PID 2>/dev/null; then
        kill $WEB_PID 2>/dev/null
        echo "   âœ… Web server stopped"
    fi
    if [ ! -z "$AI_PID" ] && kill -0 $AI_PID 2>/dev/null; then
        kill $AI_PID 2>/dev/null
        echo "   âœ… AI server stopped"
    fi
    if [ ! -z "$GUN_PID" ] && kill -0 $GUN_PID 2>/dev/null; then
        kill $GUN_PID 2>/dev/null
        echo "   âœ… Gun.js relay stopped"
    fi
    if [ ! -z "$ASL_PID" ] && kill -0 $ASL_PID 2>/dev/null; then
        kill $ASL_PID 2>/dev/null
        echo "   âœ… ASL server stopped"
    fi
    if [ ! -z "$ROBOT_PID" ] && kill -0 $ROBOT_PID 2>/dev/null; then
        kill $ROBOT_PID 2>/dev/null
        echo "   âœ… Robot executor stopped"
    fi
    if [ ! -z "$HTTPS_PID" ] && kill -0 $HTTPS_PID 2>/dev/null; then
        kill $HTTPS_PID 2>/dev/null
        echo "   âœ… HTTPS server stopped"
    fi
    
    # Fallback: kill by process name (be specific about paths)
    pkill -f "python.*asl_server" 2>/dev/null
    pkill -f "python.*https-server" 2>/dev/null
    pkill -f "python.*http.server" 2>/dev/null
    pkill -f "/opt/homebrew/bin/llama-server" 2>/dev/null
    pkill -f "/usr/local/bin/llama-server" 2>/dev/null
    pkill -f "node.*gun-relay" 2>/dev/null
    
    # Clean up temporary files
    rm -f gun-relay.js 2>/dev/null
    
    echo "ðŸ All servers stopped. Goodbye!"
    exit 0
}

# Set up signal handlers
trap cleanup SIGINT SIGTERM

echo "ðŸŒ Starting web server on port $WEB_PORT..."

# Try to start the web server with error handling
start_web_server() {
    local attempts=0
    local max_attempts=3
    
    while [ $attempts -lt $max_attempts ]; do
        if $PYTHON_CMD -m http.server $WEB_PORT > /dev/null 2>&1 & then
            WEB_PID=$!
            sleep 2
            if kill -0 $WEB_PID 2>/dev/null; then
                echo "âœ… Web server started on port $WEB_PORT"
                return 0
            fi
        fi
        
        attempts=$((attempts + 1))
        WEB_PORT=$(find_available_port $((WEB_PORT + 1)))
        echo "âš ï¸  Retrying with port $WEB_PORT..."
        sleep 1
    done
    
    echo "âŒ Failed to start web server after $max_attempts attempts"
    return 1
}

if ! start_web_server; then
    cleanup
    exit 1
fi

if [ "$AI_SERVER" = true ]; then
    echo "ðŸ¤– Preparing AI server..."
    
    # Start the AI server with better error handling
    echo "ðŸš€ Starting AI server on port $AI_PORT..."
    echo "â³ This may take a moment to download/load the model..."
    
    # Check for local model files first
    LOCAL_MODEL="models/SmolVLM/SmolVLM-500M-Instruct-Q8_0.gguf"
    LOCAL_MMPROJ="models/SmolVLM/mmproj-SmolVLM-500M-Instruct-Q8_0.gguf"
    
    if [ -f "$LOCAL_MODEL" ] && [ -f "$LOCAL_MMPROJ" ]; then
        echo "   Using local model files..."
        "$LLAMA_SERVER" \
            --model "$LOCAL_MODEL" \
            --mmproj "$LOCAL_MMPROJ" \
            --port $AI_PORT \
            --host 0.0.0.0 \
            --n-gpu-layers 0 \
            --chat-template chatml \
            --log-disable > ai-server.log 2>&1 &
    else
        # Fallback to HuggingFace download
        MMPROJ_PATH="$HOME/Library/Caches/llama.cpp/ggml-org_SmolVLM-500M-Instruct-GGUF_mmproj-SmolVLM-500M-Instruct-Q8_0.gguf"
        
        if [ -f "$MMPROJ_PATH" ]; then
            echo "   Using cached mmproj file..."
            "$LLAMA_SERVER" \
                --hf-repo ggml-org/SmolVLM-500M-Instruct-GGUF \
                --hf-file SmolVLM-500M-Instruct-Q8_0.gguf \
                --mmproj "$MMPROJ_PATH" \
                --port $AI_PORT \
                --host 0.0.0.0 \
                --n-gpu-layers 0 \
                --chat-template chatml \
                --log-disable > ai-server.log 2>&1 &
        else
            echo "   Downloading mmproj file automatically..."
            "$LLAMA_SERVER" \
                --hf-repo ggml-org/SmolVLM-500M-Instruct-GGUF \
                --hf-file SmolVLM-500M-Instruct-Q8_0.gguf \
                --mmproj ggml-org/SmolVLM-500M-Instruct-GGUF/mmproj-SmolVLM-500M-Instruct-Q8_0.gguf \
                --port $AI_PORT \
                --host 0.0.0.0 \
                --n-gpu-layers 0 \
                --chat-template chatml \
                --log-disable > ai-server.log 2>&1 &
        fi
    fi
    AI_PID=$!
    
    # Wait for server to be ready with timeout
    echo "â³ Waiting for AI server to initialize..."
    MAX_RETRIES=60
    RETRY_COUNT=0
    while [ $RETRY_COUNT -lt $MAX_RETRIES ]; do
        if curl -s "http://localhost:$AI_PORT/health" >/dev/null 2>&1; then
            echo "âœ… AI server ready!"
            break
        fi
        
        # Check if process is still running
        if ! kill -0 $AI_PID 2>/dev/null; then
            echo "âŒ AI server process died. Check ai-server.log for details."
            echo "   Last few lines of log:"
            tail -n 5 ai-server.log 2>/dev/null || echo "   (No log file found)"
            AI_SERVER=false
            break
        fi
        
        if [ $((RETRY_COUNT % 10)) -eq 0 ]; then
            echo "   Still waiting... ($RETRY_COUNT/${MAX_RETRIES})"
        fi
        
        sleep 1
        RETRY_COUNT=$((RETRY_COUNT + 1))
    done
    
    if [ $RETRY_COUNT -eq $MAX_RETRIES ]; then
        echo "âŒ AI server failed to start within timeout. Check ai-server.log for details."
        AI_SERVER=false
    fi
fi

# Start ASL Recognition Server
echo ""
echo "ðŸ¤Ÿ Starting ASL Recognition Server on port $ASL_PORT..."
if [ -f "asl_server.py" ]; then
    # Set environment variables for ASL server
    export LLAMA_SERVER_URL="http://localhost:$AI_PORT"
    export ASL_SERVER_PORT=$ASL_PORT
    $PYTHON_CMD asl_server.py > asl-server.log 2>&1 &
    ASL_PID=$!
    
    # Wait for ASL server to be ready
    echo "â³ Waiting for ASL server to initialize..."
    sleep 2
    MAX_ASL_RETRIES=30
    ASL_RETRY_COUNT=0
    while [ $ASL_RETRY_COUNT -lt $MAX_ASL_RETRIES ]; do
        if curl -s "http://localhost:$ASL_PORT/health" >/dev/null 2>&1; then
            echo "âœ… ASL Recognition Server ready!"
            break
        fi
        
        # Check if process is still running
        if ! kill -0 $ASL_PID 2>/dev/null; then
            echo "âŒ ASL server process died. Check asl-server.log for details."
            echo "   Last few lines of log:"
            tail -n 5 asl-server.log 2>/dev/null || echo "   (No log file found)"
            break
        fi
        
        if [ $((ASL_RETRY_COUNT % 5)) -eq 0 ] && [ $ASL_RETRY_COUNT -gt 0 ]; then
            echo "   Still waiting for ASL server... ($ASL_RETRY_COUNT/${MAX_ASL_RETRIES})"
        fi
        
        sleep 1
        ASL_RETRY_COUNT=$((ASL_RETRY_COUNT + 1))
    done
    
    if [ $ASL_RETRY_COUNT -eq $MAX_ASL_RETRIES ]; then
        echo "âŒ ASL server failed to start within timeout. Check asl-server.log for details."
    fi
else
    echo "âŒ asl_server.py not found. ASL recognition will not be available."
    ASL_PID=""
fi

# Start Robot Executor Server for ASL-to-Robot Control
echo ""
echo "ðŸ¤– Starting Robot Executor Server on port 5002..."
if [ -f "robot_executor.py" ]; then
    $PYTHON_CMD robot_executor.py > robot-executor.log 2>&1 &
    ROBOT_PID=$!
    
    # Wait for Robot executor to be ready
    echo "â³ Waiting for Robot executor to initialize..."
    sleep 2
    MAX_ROBOT_RETRIES=15
    ROBOT_RETRY_COUNT=0
    while [ $ROBOT_RETRY_COUNT -lt $MAX_ROBOT_RETRIES ]; do
        if curl -s "http://localhost:5002/robot/health" >/dev/null 2>&1; then
            echo "âœ… Robot Executor Server ready!"
            break
        fi
        
        # Check if process is still running
        if ! kill -0 $ROBOT_PID 2>/dev/null; then
            echo "âŒ Robot executor process died. Check robot-executor.log for details."
            echo "   Last few lines of log:"
            tail -n 5 robot-executor.log 2>/dev/null || echo "   (No log file found)"
            break
        fi
        
        if [ $((ROBOT_RETRY_COUNT % 5)) -eq 0 ] && [ $ROBOT_RETRY_COUNT -gt 0 ]; then
            echo "   Still waiting for Robot executor... ($ROBOT_RETRY_COUNT/${MAX_ROBOT_RETRIES})"
        fi
        
        sleep 1
        ROBOT_RETRY_COUNT=$((ROBOT_RETRY_COUNT + 1))
    done
    
    if [ $ROBOT_RETRY_COUNT -eq $MAX_ROBOT_RETRIES ]; then
        echo "âŒ Robot executor failed to start within timeout. Check robot-executor.log for details."
    fi
else
    echo "âŒ robot_executor.py not found. Robot control will not be available."
    ROBOT_PID=""
fi

# Start HTTPS Server for camera access
echo ""
echo "ðŸ” Starting HTTPS Server on port $HTTPS_PORT..."
if [ -f "https-server.py" ]; then
    $PYTHON_CMD https-server.py --port $HTTPS_PORT > https-server.log 2>&1 &
    HTTPS_PID=$!
    
    # Wait for HTTPS server to be ready
    sleep 2
    if kill -0 $HTTPS_PID 2>/dev/null; then
        echo "âœ… HTTPS Server started successfully!"
    else
        echo "âŒ HTTPS Server failed to start. Check https-server.log for details."
        echo "   Last few lines of log:"
        tail -n 5 https-server.log 2>/dev/null || echo "   (No log file found)"
        # Fallback to HTTP server
        echo "ðŸ”„ Falling back to HTTP server..."
        $PYTHON_CMD -m http.server $WEB_PORT > web-server.log 2>&1 &
        WEB_PID=$!
        HTTPS_PORT=$WEB_PORT
    fi
else
    echo "âš ï¸  https-server.py not found. Starting regular HTTP server..."
    $PYTHON_CMD -m http.server $WEB_PORT > web-server.log 2>&1 &
    WEB_PID=$!
    HTTPS_PORT=$WEB_PORT
fi


echo ""
echo "ðŸŽ¯ ASL Command Center Ready!"
echo "============================="
echo ""
echo "ðŸŒ Access the interface at:"
if [ "$HTTPS_PORT" -eq 8443 ] || [ "$HTTPS_PORT" -eq 443 ]; then
    echo "   ðŸ“± Primary: https://localhost:$HTTPS_PORT"
    echo "   ðŸ”’ Camera access enabled via HTTPS"
else
    echo "   ðŸ“± Primary: http://localhost:$HTTPS_PORT"
    echo "   âš ï¸  Limited camera access (HTTP only)"
fi
echo ""
echo "ï¿½ Available ASL Commands:"
echo "   Basic: Hello, Help, Thank you"
echo "   System: Stop, Go/Start"  
echo "   Robot: Robot pick up, Robot deliver"
echo "   Smart Home: Lights on/off (ready for integration)"
echo ""
echo "ðŸŽ® Demo Instructions:"
echo "   1. Open the URL above in your browser"
echo "   2. Grant camera permissions when prompted"
echo "   3. Click 'Start ASL Recognition'"
echo "   4. Try signing 'Hello' to test the system"
echo ""
echo "ðŸ”§ Server Status:"
echo "   ðŸŒ Web Interface: http://localhost:$WEB_PORT (if HTTPS fails)"
if [ "$AI_SERVER" = true ]; then
    echo "   ðŸ¤– AI Server: http://localhost:$AI_PORT (SmolVLM)"
else
    echo "   ðŸ¤– AI Server: âŒ Disabled"
fi
echo "   ðŸ“¦ Gun.js Relay: Port $GUN_PORT"
if [ ! -z "$ASL_PID" ] && kill -0 $ASL_PID 2>/dev/null; then
    echo "   ðŸ¤Ÿ ASL Server: http://localhost:$ASL_PORT"
else
    echo "   ðŸ¤Ÿ ASL Server: âŒ Not running"
fi
if [ ! -z "$ROBOT_PID" ] && kill -0 $ROBOT_PID 2>/dev/null; then
    echo "   ðŸ¤– Robot Executor: http://localhost:5002"
else
    echo "   ðŸ¤– Robot Executor: âŒ Not running"
fi
echo ""
echo "ðŸ“ Training Data will be saved to:"
echo "   ðŸ“¸ Images: ./training_data/asl_signs/"
echo "   ðŸ“ Annotations: ./training_data/annotations/"
echo ""
echo "ðŸ“‹ Troubleshooting:"
echo "   â€¢ Check *-server.log files if services aren't working"
echo "   â€¢ Use Chrome/Safari for best camera support"
echo "   â€¢ Make sure you're on localhost or HTTPS for camera access"
echo ""
echo "ðŸ† Berkeley Cal Hacks 2025 - Ready for Demo!"
echo ""
echo "ðŸ›‘ Press Ctrl+C to stop all servers"
echo ""

# Generate configuration file for front-end with FIXED ports
echo "ðŸ“ Creating configuration file with fixed ports..."
cat > config.js << EOF
// Auto-generated configuration file - DO NOT EDIT MANUALLY  
// Generated by start.sh on $(date)
window.ASL_CONFIG = {
    AI_SERVER_URL: 'http://localhost:8080',
    ASL_SERVER_URL: 'http://localhost:5001',
    GUN_RELAY_URL: 'http://localhost:8765/gun',
    WEB_SERVER_PORT: 8000,
    HTTPS_SERVER_PORT: 8443,
    AI_SERVER_AVAILABLE: $AI_SERVER
};
console.log('ASL Command Center Configuration Loaded:', window.ASL_CONFIG);
EOF

echo ""

# Wait for background processes
wait
